All necessary technical expertise resides within PolicyEngine's core team.

Pavel Makarchuk (Economist) and Ben Ogorek (Data Scientist) lead our research and evaluation capabilities. Pavel built PolicyEngine's enhanced microdata using machine learning (quantile regression forests, gradient boosting)—production systems serving 100,000+ API users. Ben developed microdata calibration systems with expertise in survey weighting and statistical modeling. Together they will design and execute the LLM benefit estimation evaluation research, creating rigorous test cases and accuracy measurements.

Nikhil Woodruff (Co-founder and CTO) architected PolicyEngine's API infrastructure and has experience integrating AI/ML into production. He'll lead AI code generation, Atlas integration, and system architecture—ensuring components work seamlessly with existing infrastructure handling millions of calculations monthly.

Max Ghenis (Co-founder and CEO), former Google data scientist, brings policy analysis and microsimulation expertise. He's led PolicyEngine's AI features: GPT-4 integrated within a month of 2023 release (now Claude), Claude Code multi-agent workflows (documented in blog posts), and policyengine-claude plugin. He'll lead rule extraction AI, Atlas development, partner integrations, and research publication. Track record shows rapid AI adoption—shipping features within weeks of model releases.

Domain expertise from three years manually encoding 1,000+ benefit and tax variables. This hands-on experience with policy language, edge cases, and validation is crucial for training AI and validating outputs. We understand where policies are ambiguous, which rules interact, what edge cases matter—knowledge distinguishing helpful AI from misleading AI.

Production AI systems already deployed: LLM policy analysis generation, Claude Code multi-agent workflows for research, policyengine-claude plugin, Atlas prototype for document retrieval. Claude Code agents currently encode TANF using merged PRs as examples—this project systematizes that with rigorous benchmarking and quality measurement.

OpenAI technical advisors critical for: optimizing prompts for complex policy language, preventing hallucinations in code generation, designing fair LLM evaluation methodology avoiding test contamination, ensuring diverse scenario coverage. Their guidance accelerates development and helps navigate ambiguous policy language, conflicting documents, and edge cases.

Partner validation from MyFriendBen, Amplifi, Starlight, Student Basic Needs Coalition, and Mirza—production API users providing real-world testing, feedback, and validation. Their frontline experience ensures AI improvements meet actual user needs.

Infrastructure: Google Cloud Platform, API systems, CI/CD pipelines, open-source repositories operational. We're adding AI to proven systems, not building from scratch.

Team capacity: 3.5 FTE (Pavel and Ben on evaluation research, Nikhil 0.75 FTE on AI infrastructure, Max 0.75 FTE on Atlas/partnerships). Sufficient for 6-month delivery without hiring.

Track record: Built PolicyEngine from zero to 100K users in 3 years, shipping features multiple times weekly. Proven ability building complex systems, maintaining production quality, responding rapidly to needs. This extends that track record into AI acceleration and systematic research.
