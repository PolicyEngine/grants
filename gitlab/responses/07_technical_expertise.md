All necessary technical expertise resides within PolicyEngine's core team:

**In-House AI/ML Expertise:**

Pavel Makarchuk, Senior Software Engineer - Built PolicyEngine's enhanced microdata using machine learning (quantile regression forests, gradient descent optimization). Experience: production ML systems, data science, statistical modeling. Will lead stochastic imputation development (Milestone 3).

Nikhil Woodruff, Co-founder and CTO - Full-stack architect with AI/ML integration experience. Built PolicyEngine's API infrastructure serving 100,000+ annual users. Experience: Python/JavaScript, distributed systems, LLM integration. Will lead code generation AI (Milestone 2) and system architecture.

Max Ghenis, Co-founder and CEO - Former Google data scientist. Expertise: policy analysis, microsimulation modeling, open-source development. Experience with LLM applications for policy explanation. Will lead rule extraction AI (Milestone 1) and partner integrations (Milestone 5).

**Domain Expertise:**

PolicyEngine team has 3+ years encoding benefit rules manually—deep understanding of policy language, edge cases, and validation requirements. We've built 1,000+ variables covering federal and state tax/benefit programs. This domain knowledge is crucial for training AI systems and validating outputs.

**AI Development Experience:**

Our team has already implemented ML enhancements to Census microdata (quantile regression forests improving income imputation accuracy 40%+). We've experimented with LLM-based policy explanations through our MCP server. We've built RAG systems for policy document search. This isn't theoretical—we have production AI/ML experience.

**External Support:**

OpenAI technical advisors - Critical for optimizing LLM prompts, structured extraction from complex documents, preventing hallucinations in code generation and explanations. Their guidance will accelerate development and ensure best practices.

Partner validation - MyFriendBen, Student Basic Needs Coalition, Starlight will provide real-world testing, user feedback, and validation of AI-generated explanations. Their frontline experience ensures outputs meet actual user needs.

**Infrastructure:**

Existing: Google Cloud Platform infrastructure, CI/CD pipelines, API systems handling 100K+ users, open-source repositories with community contributions. This foundation enables rapid AI integration without building from scratch.

**Proprietary Moat:**

While code is open-source, our competitive advantage is curated policy document corpus, validated rules, and enhanced microdata—assets that make AI training effective. Three years of manual encoding provides gold-standard training data competitors lack.

**Team Capacity:**

2.5 FTE technical capacity dedicated to this project (Pavel full-time on ML, Nikhil 0.75 FTE on infrastructure, Max 0.75 FTE on partnerships/validation). Sufficient for 6-month delivery without additional hiring—critical for timeline.

This blend of production ML experience, policy domain expertise, existing infrastructure, and focused team capacity positions PolicyEngine to deliver the complete AI stack within 6 months. Our track record: built PolicyEngine from zero to 100K users in 3 years, consistently shipping new features quarterly.
