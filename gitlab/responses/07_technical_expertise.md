All necessary technical expertise resides within PolicyEngine's core team.

Our AI and machine learning capabilities are led by Pavel Makarchuk (Economist) and Ben Ogorek (Data Scientist), who built PolicyEngine's enhanced microdata using quantile regression forests and gradient boosting—production ML systems currently serving 100,000+ API users with 40% improved income imputation accuracy. They will lead stochastic imputation development, extending these proven techniques to full household profile prediction.

Nikhil Woodruff (Co-founder and CTO) architected PolicyEngine's API infrastructure and has experience integrating AI/ML systems into production environments. He'll lead the code generation AI and overall system architecture, ensuring AI components integrate seamlessly with existing infrastructure handling millions of calculations monthly.

Max Ghenis (Co-founder and CEO), a former Google data scientist, brings expertise in microsimulation modeling and policy analysis. He's currently experimenting with LLM applications through PolicyEngine's MCP server and Claude Code agents for TANF encoding. He'll lead rule extraction AI development and partner integrations, ensuring AI outputs meet partner needs.

Our domain expertise comes from three years encoding 1,000+ benefit and tax variables manually. This hands-on experience with policy language, edge cases, and validation requirements is crucial for training AI systems and validating outputs. We understand where policies are ambiguous, which rules interact, and what edge cases matter—knowledge that makes the difference between AI that helps and AI that misleads.

We've already begun experimenting with AI-assisted encoding: Claude Code agents are helping us encode new TANF programs using specialized skills and slash commands. Early results validate that AI can draft accurate code when prompted with examples from our 1,000+ merged pull requests—human-reviewed, production-tested code that represents the gold standard for policy encoding.

OpenAI technical advisors will be critical for optimizing LLM prompts, handling structured extraction from complex policy documents, preventing hallucinations in code generation, and ensuring explanation quality. Their guidance will accelerate development and help us navigate challenges like ambiguous policy language, conflicting source documents, and edge case handling.

Partner validation comes from MyFriendBen, Amplifi, Starlight, and Student Basic Needs Coalition, who use our API in production and will provide real-world testing, user feedback, and validation of AI-generated outputs. Their frontline experience ensures our AI improvements meet actual user needs rather than theoretical benchmarks.

Our infrastructure foundation enables rapid AI integration: Google Cloud Platform, CI/CD pipelines, API systems, and open-source repositories with active community contributions. We're not building from scratch—we're adding AI to proven, operational systems.

Team capacity: 3.5 FTE dedicated to this project (Pavel and Ben full-time on ML, Nikhil 0.75 FTE on infrastructure, Max 0.75 FTE on partnerships and validation). This focused capacity is sufficient for 6-month delivery without additional hiring, which is critical for meeting the timeline.

Our track record demonstrates delivery capability: we built PolicyEngine from zero to 100,000 users in three years, consistently shipping new features quarterly. We've proven we can build complex systems, maintain production quality, and respond to partner needs. This AI project extends that track record into automation and acceleration.
