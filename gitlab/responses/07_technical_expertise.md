All necessary technical expertise resides within PolicyEngine's core team.

Our AI and machine learning capabilities are led by Pavel Makarchuk (Economist) and Ben Ogorek (Data Scientist). Pavel built PolicyEngine's enhanced microdata using quantile regression forests and gradient boosting, achieving 40% improved income imputation accuracy in production systems serving 100,000+ API users. Ben developed our microdata calibration systems and brings expertise in survey weighting and statistical modeling. Together they will lead stochastic imputation development, extending these proven techniques to predict full household profiles and fill data gaps when users provide incomplete information.

Nikhil Woodruff (Co-founder and CTO) architected PolicyEngine's API infrastructure and has experience integrating AI/ML systems into production environments. He'll lead the code generation AI and overall system architecture, ensuring AI components integrate seamlessly with existing infrastructure handling millions of calculations monthly.

Max Ghenis (Co-founder and CEO), a former Google data scientist, brings expertise in microsimulation modeling and policy analysis. He's led development of PolicyEngine's production AI features: integrated GPT-4 within a month of its 2023 release (now using Claude for policy analysis generation), built Claude Code multi-agent workflows for research automation (documented in published blog posts), and created the policyengine-claude Claude Code plugin. This track record shows rapid AI adoption and deployment capability—we ship new AI features within weeks of model releases.

Our domain expertise comes from three years encoding 1,000+ benefit and tax variables manually. This hands-on experience with policy language, edge cases, and validation requirements is crucial for training AI systems and validating outputs. We understand where policies are ambiguous, which rules interact, and what edge cases matter—knowledge that makes the difference between AI that helps and AI that misleads.

We have production AI systems deployed: LLM integration for policy analysis (GPT-4 within a month of 2023 release, now Claude), Claude Code multi-agent workflows for policy research, policyengine-claude plugin, and Atlas prototype for document retrieval. Claude Code agents currently encode TANF programs using merged PRs as examples—this project systematizes that with rigorous benchmarking.

OpenAI technical advisors will be critical for optimizing LLM prompts, handling structured extraction from complex policy documents, preventing hallucinations in code generation, and ensuring explanation quality. Their guidance will accelerate development and help us navigate challenges like ambiguous policy language, conflicting source documents, and edge case handling.

Partner validation comes from MyFriendBen, Amplifi, Starlight, and Student Basic Needs Coalition, who use our API in production and will provide real-world testing, user feedback, and validation of AI-generated outputs. Their frontline experience ensures our AI improvements meet actual user needs rather than theoretical benchmarks.

Our infrastructure foundation enables rapid AI integration: Google Cloud Platform, CI/CD pipelines, API systems, and open-source repositories with active community contributions. We're not building from scratch—we're adding AI to proven, operational systems.

Team capacity: 3.5 FTE dedicated to this project (Pavel and Ben full-time on ML, Nikhil 0.75 FTE on infrastructure, Max 0.75 FTE on partnerships and validation). This focused capacity is sufficient for 6-month delivery without additional hiring, which is critical for meeting the timeline.

Our track record demonstrates delivery capability: we built PolicyEngine from zero to 100,000 users in three years, shipping new features multiple times weekly. We've proven we can build complex systems, maintain production quality, and respond rapidly to partner needs. This AI project extends that track record into automation and acceleration.
