All necessary technical expertise resides within PolicyEngine's core team.

Pavel Makarchuk (Economist) and Ben Ogorek (Data Scientist) lead our research and evaluation capabilities. Pavel built PolicyEngine's enhanced microdata using machine learning (quantile regression forests, gradient boosting)—production systems serving 100,000+ API users. Ben developed microdata calibration systems with expertise in survey weighting and statistical modeling. Together they will design and execute the LLM benefit estimation evaluation research, creating rigorous test cases and accuracy measurements.

Nikhil Woodruff (Co-founder and CTO) architected PolicyEngine's API infrastructure and has experience integrating AI/ML into production. He'll lead AI code generation, Atlas integration, and system architecture—ensuring components work seamlessly with our existing production infrastructure.

Max Ghenis (Co-founder and CEO), former Google data scientist, brings policy analysis and microsimulation expertise. He's led PolicyEngine's AI integration, rapidly adopting new models as they release and implementing multi-agent workflows documented in our blog posts. He'll provide strategic oversight for rule extraction AI and Atlas development while managing partner relationships and research publication. His track record demonstrates rapid AI adoption, consistently shipping features within weeks of model releases.

Beyond technical skills, our team brings deep domain expertise from three years of manually encoding over 2,000 benefit and tax variables. This hands-on experience with policy language, edge cases, and validation proves crucial for training AI systems and validating their outputs. We've learned where policies contain ambiguities, which rules interact unexpectedly, and what edge cases matter most—the kind of practical knowledge that distinguishes helpful AI from misleading AI.

Production AI systems already deployed: LLM policy analysis generation, Claude Code multi-agent workflows for research, policyengine-claude plugin, Atlas prototype for document retrieval. Claude Code agents currently encode TANF using merged PRs as examples—this project systematizes that with rigorous benchmarking and quality measurement.

OpenAI technical advisors critical for: optimizing prompts for complex policy language, preventing hallucinations in code generation, designing fair LLM evaluation methodology avoiding test contamination, ensuring diverse scenario coverage. Their guidance accelerates development and helps navigate ambiguous policy language, conflicting documents, and edge cases.

Partner validation from MyFriendBen, Amplifi, Starlight, Student Basic Needs Coalition, and Mirza—production API users providing real-world testing, feedback, and validation. Their frontline experience ensures AI improvements meet actual user needs.

Infrastructure: Google Cloud Platform, API systems, CI/CD pipelines, open-source repositories operational. We're adding AI to proven systems, not building from scratch.

Team capacity: Pavel and Ben will lead evaluation research, Nikhil will oversee AI infrastructure development, and Max will provide strategic direction and partner coordination. We'll bring on additional contract developers as needed for Atlas development and code generation tasks, leveraging our network of contributors who've already worked on PolicyEngine implementations.

Track record: Built PolicyEngine from zero to 100K users in 3 years, shipping features multiple times weekly. Proven ability building complex systems, maintaining production quality, responding rapidly to needs. This extends that track record into AI acceleration and systematic research.
